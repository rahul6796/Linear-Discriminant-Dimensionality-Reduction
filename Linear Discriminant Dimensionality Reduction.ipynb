{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$1$.Fisher Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$2$.Within Group Variability(Distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$3$.Between Group Variability(Distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 .Fisher Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fisher Criterion plays an important role in dimensionality reduction. it aims at finding a feature representation by which the ${Within-Class-Distance}$ is minimized and the ${Between-class- Distance}$ is Maximized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Fisher Criterion two representative methods have been proposed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One is ${Fisher-Score}$ which is a feature selection method. The other is ${Linear -Discriminant-Analysis}$ which is a subspace learning method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key\n",
    "motivation is that, although it is based on Fisher criterion, Fisher score is not\n",
    "able to do feature combination such as LDA. The features selected by Fisher\n",
    "score are a subset of the original features. However, as we mentioned before,\n",
    "the transformed features may be more discriminative than the original features.\n",
    "On the other hand, although LDA admits feature combination, it transforms\n",
    "all the original features rather than only those useful ones as in Fisher score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above motivation, we propose a unified framework, namely Linear Discriminant Dimensionality Reduction (LDDR), integrating Fisher score\n",
    "and LDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${Note}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find such kind of unit vector ${\\vec {W}}$ such that, all points belonging to single class when projected on that vector, should givne as Minimum variances as possible but at same time between  class varinaces should be as maximum as possible( that mean we want to increase the gap)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's say that for any ${i}^{th}$ example belonging to ${0}$ class is ${X}_{i}^{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{bmatrix}\n",
    "{x}_1^{0} \\\\ {x}_2^{0} \\\\ .. \\\\ .. \\\\{x}_{N_0}^{0}\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and unit vector ${\\vec {W} \\in {R}^{N\\times{1}}}$ is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "{w}_1 \\\\ {w}_2 \\\\.. \\\\ .. \\\\ {w}_{N_0}\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and when we project on the unit vector we get the value is ${\\lambda}_i^{0}$ for ${0}$ class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\lambda}_i^{0} = {W}^T\\cdot{X}_i^{0}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and when we project on the unit vector we get the value is ${\\lambda}_i^{1}$ for ${1}$ class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\lambda}_i^{1} = {W}^T\\cdot{X}_i^{1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Within Group Variability(Distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for ${0}$ ${class}$. whithin group variability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after projection our data of ${0}$ class on unit vactor we get the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$[{\\lambda}_1^{0},{\\lambda}_3^{0},{\\lambda}_3^{0},{\\lambda}_4^{0}....................{\\lambda}_{N_0}^{0}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where ${N_0}$ is numbers of row in ${0}$ class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's calculate the mean of the projected data of ${0}$ class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\mu}_{\\lambda}^{0} = \\frac{({\\lambda}_1^{0} + {\\lambda}_2^{0}+{\\lambda}_3^{0}+................+{\\lambda}_{N_0}^{0})}{N_0}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\mu}_{\\lambda}^{0} = \\frac{({W}^T\\cdot{x}_1^{0}+{W}^T\\cdot{x}_2^{0}+{W}^T\\cdot{x}_3^{0}.......+{W}^T\\cdot{x}_{N_0}^{0})}{N_0}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\mu}_{\\lambda}^{0} = {W}^T\\cdot\\frac{({x}_1^{0}+{x}_2^{0}+{x}_3^{0}.......+{x}_{N_0}^{0})}{N_0}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now we can write as."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\mu}_{\\lambda}^{0} = {W}^T\\cdot{\\mu}^{0}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where ${{\\mu}^{0}\\in{R}^{N\\times{1}}}$ is mean vector of each features of the ${0}$ class data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "{\\mu}_1^{0} \\\\ {\\mu}_2^{0} \\\\ .. \\\\ .. \\\\ {\\mu}_{N_0}^{0}\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now our features matrix of ${0}$ class ${{X}^{0}\\in{R}^{N\\times{N_0}}}$ is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "\\\\ \\\\ {x}_1^{0} & {x}_2^{0} & .. & .. &{x}_{N_0}^{0} \\\\ \\\\ \\\\\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we are subtracting the mean of each featuers column in ${0}$ class to there own features is ${(X^{0} - {\\mu}^{0})\\in{R}^{N\\times{N_0}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "\\\\ \\\\({x}_{1}^{0} - {\\mu}_{1}^{0}) & ({x}_{2}^{0} - {\\mu}_{2}^{0})& .. & .. &({x}_{N_0}^{0} - {\\mu}_{N_0}^{0})\\\\ \\\\ \\\\ \n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we multiply the unit vector to above martix ${{W}^T\\cdot({X}^{0} - {\\mu}^{0})}$ then we get of size${\\in{R}^{1\\times{N_0}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "{W}^T({x}_1^{0} - {\\mu}_1^{0}) & {W}^T({x}_2^{0} - {\\mu}_2^{0}) & .. & .. & {W}^T({x}_{N_0}^{0} - {\\mu}_{N_0}^{0})\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also write as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "({\\lambda}_1^{0}- {\\mu}_{\\lambda}^{0}) & ({\\lambda}_2^{0}- {\\mu}_{\\lambda}^{0}) & .. & .. & ({\\lambda}_{N_0}^{0}- {\\mu}_{\\lambda}^{0})\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we multiply ${({W}^T\\cdot(X^{0} - {\\mu}^{0}))\\cdot({W}^T\\cdot({X}^{0} - {\\mu}^{0}))^T}$ of size ${\\in{R}^{1\\times{1}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our variances of the given points of ${0}$ class is.\n",
    "\\begin{equation}\n",
    "Var({\\lambda}^{0}) = \\frac{\\sum_{i=1}^{N_0}({\\lambda}_{i}^{0} - {\\mu}_{\\lambda}^{0})^2}{N_0}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explaination of the above expression is given below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "= \\frac{1}{N_0}\\cdot{[{W}^T\\cdot({X}^{0}-{\\mu}^{0})]\\cdot[{W}^T\\cdot({X}^{0}-{\\mu}^{0}]^T}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "= \\frac{1}{N_0}\\cdot{{W}^T\\cdot({X}^{0}-{\\mu}^{0})\\cdot({X}^{0}-{\\mu}^{0})^T\\cdot{W}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same for variances of the given points of ${1}$ class is.\n",
    "\\begin{equation}\n",
    "Var({\\lambda}^{1}) = \\frac{\\sum_{i=1}^{N_1}({\\lambda}_{i}^{1} - {\\mu}_{\\lambda}^{1})^2}{N_1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explaination of the above expression is given below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "= \\frac{1}{N_1}\\cdot{[{W}^T\\cdot({X}^{1}-{\\mu}^{1})]\\cdot[{W}^T\\cdot({X}^{1}-{\\mu}^{1}]^T}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "= \\frac{1}{N_1}\\cdot{{W}^T\\cdot({X}^{1}-{\\mu}^{1})\\cdot({X}^{1}-{\\mu}^{1})^T\\cdot{W}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now final we compute the Within Class Variablity is ${{\\sigma}_{w}^{2}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\sigma}_{w}^{2} = \\frac{N_0\\sum_{i=1}^{N_0}({\\lambda}_i^{0} - {\\mu}_{\\lambda}^{0}) +N_1\\sum_{i=1}^{N_1}({\\lambda}_i^{1} - {\\mu}_{\\lambda}^{1}) }{N_0 + N_1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\sigma}_{w}^{2} = \\frac{N_0\\cdot{W^T\\cdot({X}^{0} - {\\mu}^{0})\\cdot({X}^{0}- {\\mu}^{0})^T\\cdot{W} + N_1\\cdot{W^T\\cdot({X}^{1} -{\\mu}^{1})\\cdot({X}^{1} - {\\mu}^{1})^T\\cdot{W}} }}{N}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where ${N}$=${N_0}$+ ${N_1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now in above expression we are going to introduced some terms which are come from above expression is ${{S}_w\\in{R}^{N\\times{N}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{equation}\n",
    "{S}_w = {N}_0\\cdot({X}^{0} - {\\mu}^{0})\\cdot({X}^{0} - {\\mu}^{0})^T + {N}_1\\cdot({X}^{1} - {\\mu}^{1})\\cdot({X}^{1} - {\\mu}^{1})^T\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now  our final ${Within- group -Variability(distance)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{equation}\n",
    "{\\sigma}_w^{2} = {W}^T\\cdot{S}_w\\cdot{W}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 .Between Group Variability(Distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this between group variability(distance) first we calculte the ${GM}$ (Grand-Mean)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we know in advanced ${[{\\lambda}_1^{0},{\\lambda}_2^{0},{\\lambda}_3^{0},...........,{\\lambda}_{N_0}^{0}]}$ this values we get when our ${0}$ class data projecting on a unit vector.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same for ${1}$ class ${[{\\lambda}_1^{1},{\\lambda}_2^{1},{\\lambda}_3^{1},...........,{\\lambda}_{N_1}^{1}]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then there corresponding mean is ${\\mu}_{\\lambda}^{0}$ and ${{\\mu}_{\\lambda}^{1}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now Grand-Mean will be\n",
    "\\begin{equation}\n",
    "{GM}_{\\lambda} = \\frac{{\\mu}_{\\lambda}^{0} + {\\mu}_{\\lambda}^{1}}{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now we can also write as\n",
    "\\begin{equation}\n",
    "{GM}_{\\lambda} = \\frac{{W}^T\\cdot{\\mu}^{0} + {W}^T\\cdot{\\mu}^{1}}{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this ${{\\mu}^{0}}$ and ${{\\mu}^{1}}$ is the mean vectors of each features vectors of there corresponding classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{GM}_{\\lambda} = W^T\\cdot\\frac{({\\mu}^0 + {\\mu}^1)}{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{GM}_{\\lambda}  = W^T\\cdot{GM}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and this ${GM}$ is equal to Grand-mean of the each features of there crresponding class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now our Between group Variability(distance) is represented as ${{\\sigma}_{B}^{2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\sigma}_{B}^{2} = \\frac{\\sum_{i=0}^{1}({\\mu}_{\\lambda}^{i} - {GM}_{\\lambda})}{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\sigma}_{B}^{2} = \\frac{\\sum_{i=0}^{1}(W^T\\cdot{\\mu}^{i} - W^T\\cdot{GM})^2}{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's explain the above expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean vectors two class ${{\\mu}\\in{R}^{N\\times{2}}}$ is ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "\\\\ \\\\ {\\mu}^{0} & {\\mu}^{1} \\\\ \\\\ \\\\  \n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and your Grand-Mean of each features column there corresponding ${{GM}\\in{R}^{N\\times{1}}}$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "{GM}_{1} \\\\ {GM}_{2} \\\\ .. \\\\ .. \\\\{GM}_{N}\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we are subtracting Grand mean from Mean vector of each classes ${({\\mu} - {GM})\\in{R}^{N\\times{2}}}$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "\\\\ \\\\ ({\\mu}^{0} - {GM}) & ({\\mu}^{1} - {GM}) \\\\ \\\\  \n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now our Between group variability(Distance)  ${\\sigma}_{B}^{2}$we can write as ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\sigma}_{B}^{2} = \\frac{\\sum_{i=0}^{1}({\\mu}_{\\lambda}^{i} - {GM}_{\\lambda})^{2}}{2} = \\frac{W^T\\cdot({\\mu} - {GM})\\cdot({\\mu} - {GM})^T\\cdot{W}}{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we are going to introduced some trem ${\\in{R}^{N\\times{N}}}$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{S}_{B} = \\frac{({\\mu} - {GM})\\cdot({\\mu} - {GM})^T}{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${{S}_{B}}$ is called the Between class Scatter Matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\sigma}_{B}^{2} = {W}^T\\cdot{{S}_{B}}\\cdot{W}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now by fisher criterion we are going to maximized the ratio of this two variances which is represented by ${C(W)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "C(W) = \\frac{Between-class- variability(distance)}{Within-class-variability(distance)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so our optimization problem is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\max_{} C(W) = \\frac{{\\sigma}_{B}^{2} }{{\\sigma}_{w}^{2}} = \\frac{W^T\\cdot{{S}_{B}}\\cdot{W}}{W^T\\cdot{{S}_{w}}\\cdot{W}} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we assume that ${{S}_{B}}$ is ${non-singular-matrix}$ ${\\in{R}^{2\\times{2}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "{\\sigma}_{B_1}^{2} & {0} \\\\ {0} & {\\sigma}_{B_2}^{2}\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same for we assme that ${{S}_{w}}$ is also ${non-singular-matrix}$ ${\\in{R}^{2\\times{2}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "{\\sigma}_{w_1}^{2} & {0} \\\\ {0} & {\\sigma}_{w_2}^{2}\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and unit vector ${W}$ is${\\in{R}^{2\\times{1}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "{w}_1 \\\\ {w}_2\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when we solve the above equation we get some result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "W^T\\cdot{{S}_{B}}\\cdot{W}  = {w}_{1}^{2}\\cdot{{\\sigma}_{B_1}^2} + {w}_{2}^{2}\\cdot{{\\sigma}_{B_2}^{2}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "W^T\\cdot{{S}_{w}}\\cdot{W}  = {w}_{1}^{2}\\cdot{{\\sigma}_{w_1}^2} + {w}_{2}^{2}\\cdot{{\\sigma}_{w_2}^{2}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we are maximized this ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\max_{}C(W)=C({w}_1,{w}_2) = \\frac{{w}_{1}^{2}\\cdot{{\\sigma}_{B_1}^2} + {w}_{2}^{2}\\cdot{{\\sigma}_{B_2}^{2}}}{{w}_{1}^{2}\\cdot{{\\sigma}_{w_1}^2} + {w}_{2}^{2}\\cdot{{\\sigma}_{w_2}^{2}}} = \\frac{f({w}_1,{w}_2)}{g({w}_1,{w}_2)}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for maximization we take partial derivative w.r.t both parameters of above function and make them equal to ${0}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-part.\n",
    "\\begin{equation}\n",
    "\\frac{{\\partial}}{{\\partial {w}_1}}\\cdot{C({w}_1,{w}_2)}  = 0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-part.\n",
    "\\begin{equation}\n",
    "\\frac{{\\partial}}{{\\partial {w}_2}}\\cdot{C({w}_1,{w}_2)}  = 0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's compute 1-part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\partial}{\\partial {w}_1}\\cdot{\\frac{f({w}_1,{w}_2)}{g({w}_1,{w}_2)}} = \\frac{g({w}_1,{w}_2)\\cdot{2{w}_{1}{\\sigma}_{B_1}^{2}- f({w_1},{w}_2)\\cdot{2{w}_1{\\sigma}_{w_1}^2}}}{(g({w}_1,{w}_2))^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after keeping equal to ${0}$ then answer will come is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{f({w}_1,{w}_2)}{g({w}_1,{w}_2)}\\cdot{w}_1  = \\frac{{\\sigma}_{B_1}^{2}}{{\\sigma}_{w_1}^{2}} \\cdot{w}_1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "C({w}_1,{w}_2)\\cdot{w}_1 =  \\frac{{\\sigma}_{B_1}^{2}}{{\\sigma}_{w_1}^{2}} \\cdot{w}_1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when you solve for ${w}_2$ then result is look' like that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\frac{f({w}_1,{w}_2)}{g({w}_1,{w}_2)}\\cdot{w}_2  = \\frac{{\\sigma}_{B_2}^{2}}{{\\sigma}_{w_2}^{2}} \\cdot{w}_2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "C({w}_1,{w}_2)\\cdot{w}_2 =  \\frac{{\\sigma}_{B_2}^{2}}{{\\sigma}_{w_2}^{2}} \\cdot{w}_2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now our final results after partial derivatives is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "C(W)\\cdot{w}_1 =  \\frac{{\\sigma}_{B_1}^{2}}{{\\sigma}_{w_1}^{2}} \\cdot{w}_1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "C(W)\\cdot{w}_2 =  \\frac{{\\sigma}_{B_2}^{2}}{{\\sigma}_{w_2}^{2}} \\cdot{w}_2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also write."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below this two result through which we try to get some information. and if we combined them we get some intresting result which are given below after some lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " \\frac{{\\sigma}_{B_1}^{2}}{{\\sigma}_{w_1}^{2}} \\cdot{w}_1 = C(W)\\cdot{w}_1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " \\frac{{\\sigma}_{B_2}^{2}}{{\\sigma}_{w_2}^{2}} \\cdot{w}_2 =C(W)\\cdot{w}_2 \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we assume that ${{S}_{B}}$ is ${non-singular-matrix}$ ${\\in{R}^{2\\times{2}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "{\\sigma}_{B_1}^{2} & {0} \\\\ {0} & {\\sigma}_{B_2}^{2}\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same for we assme that ${{S}_{w}}$ is also ${non-singular-matrix}$ ${\\in{R}^{2\\times{2}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "{\\sigma}_{w_1}^{2} & {0} \\\\ {0} & {\\sigma}_{w_2}^{2}\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we take invers of the ${{S}_{w}}$ is ${{S}_{w}^{-1}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "\\frac{1}{{\\sigma}_{w_1}^{2}} & {0} \\\\ {0} & \\frac{1}{{\\sigma}_{w_2}^{2}}\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we taking dot product of ${{S}_{B}}$ with ${{S}_{w}^{-1}}$ is${({S}_{B}\\cdot{{S}_{w}^{-1}})}$  of size ${\\in{R}^{2\\times{2}}}$ then we get matrix look's like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "\\frac{{\\sigma}_{B_1}^2}{{\\sigma}_{w_1}^{2}}  & 0 \\\\ 0  &\\frac{{\\sigma}_{B_2}^2}{{\\sigma}_{w_2}^{2}}\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are write final equation which express all the above calculation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "({S}_{B}\\cdot{{S}_{w}^{-1}})\\cdot{W} = C(W)\\cdot{W}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are defined all terms  of this equation ${W}$ is ${\\in{R}^{2\\times{1}}}$ unit vector where we are projecting our data. and ${C(W)}$ is scalar quantity because this ratio of two Variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am also give you some information about this above equation. Is that when we Multiply a Matrix with a vector and and we get that vector of some scalar quantity times.  this whole process is happen in the case of EVD(Eigen Value Decompostion)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in EVD this scalar quantity ${C(W)}$  we can defined by ${\\lambda}$ which is Matrix of Eigen Values. and this eigen values are in this decraesing order somthing like that ${\\lambda}_1$ $>$ ${\\lambda}_2$ $>$.......${\\lambda}_{N}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we intersting to find eigen vector corresponding  greater eigen values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And In Linear Discriminant Dimensionality Reduction we are also try to find a unit vector that which they have greatest eigen value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
