{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$1$.Fisher Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$2$.Within Group Variability(Distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$3$.Between Group Variability(Distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 .Fisher Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fisher Criterion plays an important role in dimensionality reduction. it aims at finding a feature representation by which the ${Within-Class-Distance}$ is minimized and the ${Between-class- Distance}$ is Maximized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Fisher Criterion two representative methods have been proposed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One is ${Fisher-Score}$ which is a feature selection method. The other is ${Linear -Discriminant-Analysis}$ which is a subspace learning method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key\n",
    "motivation is that, although it is based on Fisher criterion, Fisher score is not\n",
    "able to do feature combination such as LDA. The features selected by Fisher\n",
    "score are a subset of the original features. However, as we mentioned before,\n",
    "the transformed features may be more discriminative than the original features.\n",
    "On the other hand, although LDA admits feature combination, it transforms\n",
    "all the original features rather than only those useful ones as in Fisher score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above motivation, we propose a unified framework, namely Linear Discriminant Dimensionality Reduction (LDDR), integrating Fisher score\n",
    "and LDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${Note}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find such kind of unit vector ${\\vec {W}}$ such that, all points belonging to single class when projected on that vector, should givne as Minimum variances as possible but at same time between  class varinaces should be as maximum as possible( that mean we want to increase the gap)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's say that for any ${i}^{th}$ example belonging to ${0}$ class is ${X}_{i}^{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{bmatrix}\n",
    "{x}_1^{0} \\\\ {x}_2^{0} \\\\ .. \\\\ .. \\\\{x}_{N_0}^{0}\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and unit vector ${\\vec {W} \\in {R}^{N\\times{1}}}$ is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "{w}_1 \\\\ {w}_2 \\\\.. \\\\ .. \\\\ {w}_{N_0}\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and when we project on the unit vector we get the value is ${\\lambda}_i^{0}$ for ${0}$ class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\lambda}_i^{0} = {W}^T\\cdot{X}_i^{0}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and when we project on the unit vector we get the value is ${\\lambda}_i^{1}$ for ${1}$ class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\lambda}_i^{1} = {W}^T\\cdot{X}_i^{1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Within Group Variability(Distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for ${0}$ ${class}$. whithin group variability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after projection our data of ${0}$ class on unit vactor we get the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$[{\\lambda}_1^{0},{\\lambda}_3^{0},{\\lambda}_3^{0},{\\lambda}_4^{0}....................{\\lambda}_{N_0}^{0}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where ${N_0}$ is numbers of row in ${0}$ class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's calculate the mean of the projected data of ${0}$ class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\mu}_{\\lambda}^{0} = \\frac{({\\lambda}_1^{0} + {\\lambda}_2^{0}+{\\lambda}_3^{0}+................+{\\lambda}_{N_0}^{0})}{N_0}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\mu}_{\\lambda}^{0} = \\frac{({W}^T\\cdot{x}_1^{0}+{W}^T\\cdot{x}_2^{0}+{W}^T\\cdot{x}_3^{0}.......+{W}^T\\cdot{x}_{N_0}^{0})}{N_0}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\mu}_{\\lambda}^{0} = {W}^T\\cdot\\frac{({x}_1^{0}+{x}_2^{0}+{x}_3^{0}.......+{x}_{N_0}^{0})}{N_0}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now we can write as."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\mu}_{\\lambda}^{0} = {W}^T\\cdot{\\mu}^{0}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where ${{\\mu}^{0}\\in{R}^{N\\times{1}}}$ is mean vector of each features of the ${0}$ class data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "{\\mu}_1^{0} \\\\ {\\mu}_2^{0} \\\\ .. \\\\ .. \\\\ {\\mu}_{N_0}^{0}\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now our features matrix of ${0}$ class ${{X}^{0}\\in{R}^{N\\times{N_0}}}$ is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "\\\\ \\\\ {x}_1^{0} & {x}_2^{0} & .. & .. &{x}_{N_0}^{0} \\\\ \\\\ \\\\\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we are subtracting the mean of each featuers column in ${0}$ class to there own features is ${(X^{0} - {\\mu}^{0})\\in{R}^{N\\times{N_0}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "\\\\ \\\\({x}_{1}^{0} - {\\mu}_{1}^{0}) & ({x}_{2}^{0} - {\\mu}_{2}^{0})& .. & .. &({x}_{N_0}^{0} - {\\mu}_{N_0}^{0})\\\\ \\\\ \\\\ \n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we multiply the unit vector to above martix ${{W}^T\\cdot({X}^{0} - {\\mu}^{0})}$ then we get of size${\\in{R}^{1\\times{N_0}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "{W}^T({x}_1^{0} - {\\mu}_1^{0}) & {W}^T({x}_2^{0} - {\\mu}_2^{0}) & .. & .. & {W}^T({x}_{N_0}^{0} - {\\mu}_{N_0}^{0})\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also write as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{bmatrix}\n",
    "({\\lambda}_1^{0}- {\\mu}_{\\lambda}^{0}) & ({\\lambda}_2^{0}- {\\mu}_{\\lambda}^{0}) & .. & .. & ({\\lambda}_{N_0}^{0}- {\\mu}_{\\lambda}^{0})\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we multiply ${({W}^T\\cdot(X^{0} - {\\mu}^{0}))\\cdot({W}^T\\cdot({X}^{0} - {\\mu}^{0}))^T}$ of size ${\\in{R}^{1\\times{1}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our variances of the given points of ${0}$ class is.\n",
    "\\begin{equation}\n",
    "Var({\\lambda}^{0}) = \\frac{\\sum_{i=1}^{N_0}({\\lambda}_{i}^{0} - {\\mu}_{\\lambda}^{0})^2}{N_0}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explaination of the above expression is given below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "= \\frac{1}{N_0}\\cdot{[{W}^T\\cdot({X}^{0}-{\\mu}^{0})]\\cdot[{W}^T\\cdot({X}^{0}-{\\mu}^{0}]^T}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "= \\frac{1}{N_0}\\cdot{{W}^T\\cdot({X}^{0}-{\\mu}^{0})\\cdot({X}^{0}-{\\mu}^{0})^T\\cdot{W}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same for variances of the given points of ${1}$ class is.\n",
    "\\begin{equation}\n",
    "Var({\\lambda}^{1}) = \\frac{\\sum_{i=1}^{N_1}({\\lambda}_{i}^{1} - {\\mu}_{\\lambda}^{1})^2}{N_1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explaination of the above expression is given below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "= \\frac{1}{N_1}\\cdot{[{W}^T\\cdot({X}^{1}-{\\mu}^{1})]\\cdot[{W}^T\\cdot({X}^{1}-{\\mu}^{1}]^T}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "= \\frac{1}{N_1}\\cdot{{W}^T\\cdot({X}^{1}-{\\mu}^{1})\\cdot({X}^{1}-{\\mu}^{1})^T\\cdot{W}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now final we compute the Within Class Variablity is ${{\\sigma}_{w}^{2}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\sigma}_{w}^{2} = \\frac{N_0\\sum_{i=1}^{N_0}({\\lambda}_i^{0} - {\\mu}_{\\lambda}^{0}) +N_1\\sum_{i=1}^{N_1}({\\lambda}_i^{1} - {\\mu}_{\\lambda}^{1}) }{N_0 + N_1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\sigma}_{w}^{2} = \\frac{N_0\\cdot{W^T\\cdot({X}^{0} - {\\mu}^{0})\\cdot({X}^{0}- {\\mu}^{0})^T\\cdot{W} + N_1\\cdot{W^T\\cdot({X}^{1} -{\\mu}^{1})\\cdot({X}^{1} - {\\mu}^{1})^T\\cdot{W}} }}{N}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where ${N}$=${N_0}$+ ${N_1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now in above expression we are going to introduced some terms which are come from above expression is ${{S}_w\\in{R}^{N\\times{N}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{equation}\n",
    "{S}_w = {N}_0\\cdot({X}^{0} - {\\mu}^{0})\\cdot({X}^{0} - {\\mu}^{0})^T + {N}_1\\cdot({X}^{1} - {\\mu}^{1})\\cdot({X}^{1} - {\\mu}^{1})^T\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now  our final ${Within- group -Variability(distance)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{equation}\n",
    "{\\sigma}_w^{2} = {W}^T\\cdot{S}_w\\cdot{W}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 .Between Group Variability(Distance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this between group variability(distance) first we calculte the ${GM}$ (Grand-Mean)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we know in advanced ${[{\\lambda}_1^{0},{\\lambda}_2^{0},{\\lambda}_3^{0},...........,{\\lambda}_{N_0}^{0}]}$ this values we get when our ${0}$ class data projecting on a unit vector.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same for ${1}$ class ${[{\\lambda}_1^{1},{\\lambda}_2^{1},{\\lambda}_3^{1},...........,{\\lambda}_{N_1}^{1}]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then there corresponding mean is ${\\mu}_{\\lambda}^{0}$ and ${{\\mu}_{\\lambda}^{1}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now Grand-Mean will be\n",
    "\\begin{equation}\n",
    "{GM}_{\\lambda} = \\frac{{\\mu}_{\\lambda}^{0} + {\\mu}_{\\lambda}^{1}}{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so now we can also write as\n",
    "\\begin{equation}\n",
    "{GM}_{\\lambda} = \\frac{{W}^T\\cdot{\\mu}^{0} + {W}^T\\cdot{\\mu}^{1}}{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this ${{\\mu}^{0}}$ and ${{\\mu}^{1}}$ is the mean vectors of each features vectors of there corresponding classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{GM}_{\\lambda} = W^T\\cdot\\frac{({\\mu}^0 + {\\mu}^1)}{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{GM}_{\\lambda}  = W^T\\cdot{GM}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and this ${GM}$ is equal to Grand-mean of the each features of there crresponding class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now our Between group Variability(distance) is represented as ${{\\sigma}_{B}^{2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\sigma}_{B}^{2} = \\frac{\\sum_{i=0}^{1}({\\mu}_{\\lambda}^{i} - {GM}_{\\lambda})}{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\sigma}_{B}^{2} = \\frac{\\sum_{i=0}^{1}(W^T\\cdot{\\mu}^{i} - W^T\\cdot{GM})^2}{2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's explain the above expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
